{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "\n",
    "# Read in the .csv files as Pandas DataFrame\n",
    "building = pd.read_csv(data_dir + 'building_metadata.csv')\n",
    "train = pd.read_csv(data_dir + 'train.csv')\n",
    "weather_train = pd.read_csv(data_dir + 'weather_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(building, left_on = \"building_id\", right_on = \"building_id\", how = \"left\")\n",
    "train = train.merge(weather_train, left_on = [\"site_id\", \"timestamp\"], right_on = [\"site_id\", \"timestamp\"], how = \"left\")\n",
    "\n",
    "\n",
    "del weather_train\n",
    "\n",
    "\n",
    "train[\"timestamp\"] = pd.to_datetime(train[\"timestamp\"])\n",
    "train[\"hour\"] = train[\"timestamp\"].dt.hour\n",
    "train[\"day\"] = train[\"timestamp\"].dt.day\n",
    "train[\"weekend\"] = train[\"timestamp\"].dt.weekday\n",
    "train[\"month\"] = train[\"timestamp\"].dt.month\n",
    "\n",
    "train = train.drop(\"timestamp\", axis = 1)\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "train[\"primary_use\"] = le.fit_transform(train[\"primary_use\"])\n",
    "\n",
    "train = train.drop([\"precip_depth_1_hr\", \"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"site_id\", \"floor_count\"],axis=1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.log1p(train[\"meter_reading\"])\n",
    "target\n",
    "\n",
    "\n",
    "train = train.drop([\"meter_reading\"],axis=1)\n",
    "\n",
    "\n",
    "train, NAlist = reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"building_id\", \"primary_use\", \"hour\", \"day\", \"weekend\", \"month\", \"meter\",\"square_feet\", \"year_built\", \"air_temperature\", \"cloud_coverage\",\"dew_temperature\"]\n",
    "num_folds = 3\n",
    "kf = KFold(n_splits = num_folds, shuffle = False)\n",
    "error = 0\n",
    "models = []\n",
    "evals_results = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    if i + 1 < num_folds:\n",
    "        continue\n",
    "    print(train_index.max(), test_index.min())\n",
    "    train_X = train[data].iloc[train_index]\n",
    "    test_X = train[data].iloc[test_index]\n",
    "    train_y = target.iloc[train_index]\n",
    "    test_y = target.iloc[test_index]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(train_X[train_y > 0], train_y[train_y > 0])\n",
    "    lgb_test = lgb.Dataset(test_X[test_y > 0] , test_y[test_y > 0])\n",
    "    evals_result = {}\n",
    "    params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': {'rmse'},\n",
    "            'learning_rate': 0.6,\n",
    "            'feature_fraction': 0.7,\n",
    "            'bagging_fraction': 0.7,\n",
    "            'bagging_freq' : 4\n",
    "            }\n",
    "    model = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=2000,\n",
    "                valid_sets=(lgb_train, lgb_test),\n",
    "               early_stopping_rounds=30,\n",
    "               verbose_eval = 25,\n",
    "               evals_result = evals_result\n",
    "                           )\n",
    "    models.append(model)\n",
    "    evals_results.append(evals_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, evals_result in zip(models, evals_results):\n",
    "    f, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize=(15, 6))\n",
    "    lgb.plot_importance(model, ax=ax1)\n",
    "    lgb.plot_metric(evals_result, metric='rmse', ax=ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(model.feature_importance(), model.feature_name()),reverse = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
